{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# üèÜ AI Hackathon Survival Bible\n",
    "\n",
    "This notebook contains ready-to-use code snippets for:\n",
    "\n",
    "- Data handling\n",
    "- Image tasks\n",
    "- NLP\n",
    "- Generative AI\n",
    "- Speech\n",
    "- Tabular ML\n",
    "- Web scraping\n",
    "- Visualization\n",
    "- Deployment\n",
    "\n",
    "Run any cell to directly test functionality. Use this as your hackathon Swiss army knife!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data",
   "metadata": {},
   "source": ["## Data Handling"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load and inspect\n",
    "# df = pd.read_csv(\"data.csv\")\n",
    "# df.info(); df.describe()\n",
    "\n",
    "# Cleaning\n",
    "# df.dropna(); df.fillna(0)\n",
    "# df['col'] = df['col'].apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "image",
   "metadata": {},
   "source": ["## Image Tasks"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "image-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Read\n",
    "# img = cv2.imread(\"img.png\")\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# edges = cv2.Canny(img, 100, 200)\n",
    "\n",
    "# OCR\n",
    "# text = pytesseract.image_to_string(img)\n",
    "\n",
    "# Torchvision pretrained\n",
    "# from torchvision import models, transforms\n",
    "# import torch\n",
    "# model = models.resnet18(pretrained=True)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nlp",
   "metadata": {},
   "source": ["## NLP"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nlp-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summ = pipeline(\"summarization\")\n",
    "qa = pipeline(\"question-answering\")\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "sent = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Examples:\n",
    "# summ(\"Long article here\")\n",
    "# qa({\"context\": \"Priya works in healthcare\", \"question\": \"Who works in healthcare?\"})\n",
    "# ner(\"Elon founded SpaceX\")\n",
    "# sent(\"I love this!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gen",
   "metadata": {},
   "source": ["## Generative AI"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gen-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text-to-Image\n",
    "# from diffusers import StableDiffusionPipeline\n",
    "# import torch\n",
    "# pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\").to(\"cuda\")\n",
    "# img = pipe(\"a futuristic cityscape\").images[0]\n",
    "# img.save(\"gen.png\")\n",
    "\n",
    "# LLM Example\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# tok = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "# inp = tok(\"AI will change\", return_tensors=\"pt\")\n",
    "# out = model.generate(**inp, max_length=50)\n",
    "# print(tok.decode(out[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speech",
   "metadata": {},
   "source": ["## Speech"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speech-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "# Speech-to-Text\n",
    "# r = sr.Recognizer()\n",
    "# with sr.AudioFile(\"audio.wav\") as src:\n",
    "#     text = r.recognize_google(r.record(src))\n",
    "\n",
    "# Text-to-Speech\n",
    "# engine = pyttsx3.init()\n",
    "# engine.say(\"Hackathon Winner\")\n",
    "# engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tabular",
   "metadata": {},
   "source": ["## Tabular ML"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tabular-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Classification example\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# model = RandomForestClassifier().fit(X_train, y_train)\n",
    "# print(accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "# Clustering\n",
    "# kmeans = KMeans(n_clusters=3).fit(X)\n",
    "# print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "web",
   "metadata": {},
   "source": ["## Web"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "web-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Scraping\n",
    "# html = requests.get(\"https://example.com\").text\n",
    "# soup = BeautifulSoup(html, \"html.parser\")\n",
    "# print(soup.title.text)\n",
    "\n",
    "# API\n",
    "# resp = requests.get(\"https://api.github.com/users/octocat\")\n",
    "# print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz",
   "metadata": {},
   "source": ["## Visualization"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viz-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Simple Plot\n",
    "# plt.plot([1,2,3],[3,2,1]); plt.show()\n",
    "\n",
    "# Heatmap\n",
    "# sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deploy",
   "metadata": {},
   "source": ["## Deployment"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deploy-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit\n",
    "# import streamlit as st\n",
    "# st.title(\"Hackathon Demo\")\n",
    "# txt = st.text_input(\"Enter text:\")\n",
    "# st.write(\"You said:\", txt)\n",
    "\n",
    "# Gradio\n",
    "# import gradio as gr\n",
    "# def greet(name): return f\"Hello {name}\"\n",
    "# gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\").launch()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
